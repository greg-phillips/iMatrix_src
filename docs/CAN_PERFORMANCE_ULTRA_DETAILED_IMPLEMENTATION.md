# CAN Performance - ULTRA DETAILED Staged Implementation

**Date**: November 7, 2025
**Branch**: feature/improve-can-performance (iMatrix + Fleet-Connect-1)
**Critical Issue**: 90.5% packet drop rate (942,605 of 1,041,286 dropped)

**Architecture**: Multi-threaded with async logging to eliminate all I/O blocking

---

## üéØ ULTRA-COMPREHENSIVE OVERVIEW

### The 5-Stage Implementation:

| Stage | Goal | Impact | Time | Risk |
|-------|------|--------|------|------|
| **1** | Increase buffers | Drops: 90% ‚Üí 20% | 1hr | LOW |
| **2** | Async log queue | Eliminate printf blocking | 6hr | MED |
| **3** | Processing thread | Decouple from main loop | 8hr | MED |
| **4** | O(1) allocation | Faster alloc at scale | 6hr | MED |
| **5** | Profiling + tuning | Drops: < 1% | 4hr | LOW |

**Total Estimated Time**: 25 hours over 1-2 weeks
**Expected Result**: Drop rate 90.5% ‚Üí < 1%

---

## üèóÔ∏è FINAL ARCHITECTURE (All Stages Complete)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Thread 1: TCP Server (can_server.c:tcp_server_thread)          ‚îÇ
‚îÇ   Receives network data                                         ‚îÇ
‚îÇ   Parses PCAN/APTERA format                                    ‚îÇ
‚îÇ   ‚Üì                                                             ‚îÇ
‚îÇ   canFrameHandlerWithTimestamp()                               ‚îÇ
‚îÇ   - can_ring_buffer_alloc() ‚Üê O(1) free list (Stage 4)        ‚îÇ
‚îÇ   - unified_queue_enqueue()                                    ‚îÇ
‚îÇ   - ASYNC_LOG() instead of printf ‚Üê Stage 2                    ‚îÇ
‚îÇ   ‚Üì                                                             ‚îÇ
‚îÇ   [Unified Queue: 12,000 capacity] ‚Üê Stage 1                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚Üì CAN Messages
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Thread 2: CAN Processing (NEW - Stage 3)                       ‚îÇ
‚îÇ   while (!shutdown):                                            ‚îÇ
‚îÇ     - unified_queue_dequeue_batch(200 msgs) ‚Üê Stage 1          ‚îÇ
‚îÇ     - for each message:                                         ‚îÇ
‚îÇ         process_rx_can_msg()                                    ‚îÇ
‚îÇ         - Extract signals                                       ‚îÇ
‚îÇ         - Write to MM2                                         ‚îÇ
‚îÇ         - ASYNC_LOG() if needed                                ‚îÇ
‚îÇ     - return_to_source_pool()                                  ‚îÇ
‚îÇ     - sleep(1ms)                                               ‚îÇ
‚îÇ   [Profiling instrumentation] ‚Üê Stage 5                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚Üì Log Messages
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Async Log Queue (NEW - Stage 2)                               ‚îÇ
‚îÇ   - Lock-free or mutex-protected ring buffer                   ‚îÇ
‚îÇ   - 10,000 message capacity (2.5MB)                           ‚îÇ
‚îÇ   - Pre-formatted messages (vsnprintf before enqueue)          ‚îÇ
‚îÇ   - Drop oldest if full (prevents blocking)                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚Üì Dequeue for printing
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Thread 3: Main Loop / CLI                                      ‚îÇ
‚îÇ   Every cycle:                                                  ‚îÇ
‚îÇ     - Process network                                           ‚îÇ
‚îÇ     - Process uploads                                           ‚îÇ
‚îÇ     - async_log_flush(100) ‚Üê Print logs ‚Üê Stage 2              ‚îÇ
‚îÇ     - Process CLI commands                                      ‚îÇ
‚îÇ     - Other tasks                                              ‚îÇ
‚îÇ   CAN processing NOT in main loop ‚Üê Stage 3                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìã STAGE 1: IMMEDIATE BUFFER INCREASE

**Duration**: 1 hour (30min implementation + 30min testing)
**Files Modified**: 2
**Lines Changed**: ~10
**Risk Level**: ‚¨ú‚¨ú‚¨ú‚¨ú‚¨ú (1/5 - Very Low)

### Implementation Steps:

#### Step 1.1.1: Backup Current Code
```bash
cd /home/greg/iMatrix/iMatrix_Client/iMatrix
git status
# Verify on feature/improve-can-performance branch

# Create safety tag
git tag before-buffer-increase
```

#### Step 1.1.2: Modify CAN_MSG_POOL_SIZE

**File**: `canbus/can_utils.c`
**Line**: 122
**Current Value**: 500
**New Value**: 4000

**Exact Change**:
```c
// Line 122 BEFORE:
#define CAN_MSG_POOL_SIZE               500

// Line 122 AFTER:
/*
 * CAN Message Pool Size - Increased for Performance
 *
 * Each CAN bus (CAN0, CAN1, Ethernet) has a dedicated message pool.
 * At peak traffic of 2,117 fps, a 4000-message buffer provides:
 * - 1.89 seconds of buffering (4000 / 2117)
 * - At normal 829 fps: 4.83 seconds of buffering
 *
 * Memory cost per bus: 4000 √ó 24 bytes = 96 KB
 * Total (3 buses): 288 KB ‚Üê Acceptable for 1GB RAM system
 *
 * Performance Impact:
 * - BEFORE: 500 msgs, 236ms headroom, 90% drops
 * - AFTER:  4000 msgs, 1.9sec headroom, < 20% drops expected
 *
 * History:
 * - Original: 500 (Nov 2024)
 * - Increased: 4000 (Nov 7, 2025 - performance crisis fix)
 */
#define CAN_MSG_POOL_SIZE               4000
```

**Verification**:
```bash
# Check the change
grep -A5 "CAN_MSG_POOL_SIZE" canbus/can_utils.c | head -10

# Find all usages
grep -n "CAN_MSG_POOL_SIZE" canbus/*.c canbus/*.h

# Expected usages:
# - can_utils.c:122 - Definition
# - can_utils.c:155-157 - Array declarations (auto-sized)
# - can_utils.c:160-162 - Tracking arrays (auto-sized)
# - can_utils.c:multiple - Initialization calls (parameter)
# - can_ring_buffer.h:44 - May have duplicate (check consistency)
```

#### Step 1.1.3: Check Ring Buffer Header Consistency

**File**: `canbus/can_ring_buffer.h`
**Search for**: Duplicate `CAN_MSG_POOL_SIZE` definition

```bash
grep -n "CAN_MSG_POOL_SIZE" canbus/can_ring_buffer.h
```

**If found** (line 44):
```c
// BEFORE:
#define CAN_MSG_POOL_SIZE       500

// AFTER: (Must match can_utils.c)
#define CAN_MSG_POOL_SIZE       4000
```

**If not found**: No action needed (good - single source of truth)

#### Step 1.1.4: Modify UNIFIED_QUEUE_SIZE

**File**: `canbus/can_unified_queue.h`
**Line**: 68
**Current**: 1500
**New**: 12000

**Exact Change**:
```c
// Line 68 BEFORE:
#define UNIFIED_QUEUE_SIZE          1500    /**< Total queue capacity (3 buses √ó 500) */

// Line 68 AFTER:
/**
 * Unified Queue Total Capacity
 *
 * Must be >= sum of all bus ring buffers to avoid artificial bottleneck.
 * With 3 buses √ó 4000 messages each = 12000 total.
 *
 * Memory allocated dynamically via malloc():
 * - 12000 √ó sizeof(can_msg_t*) = 12000 √ó 8 = 96 KB
 *
 * Performance: Queue should never be the bottleneck.
 * Ring buffers fill first (intended behavior).
 *
 * History:
 * - Original: 1500 (3 √ó 500)
 * - Increased: 12000 (3 √ó 4000) - Nov 7, 2025
 */
#define UNIFIED_QUEUE_SIZE          12000
```

#### Step 1.1.5: Modify MAX_BATCH_SIZE

**File**: `canbus/can_unified_queue.h`
**Line**: 69
**Current**: 100
**New**: 200

**Exact Change**:
```c
// Line 69 BEFORE:
#define MAX_BATCH_SIZE              100     /**< Max messages dequeued per call */

// Line 69 AFTER:
/**
 * Maximum Batch Size for Processing
 *
 * Number of messages dequeued per call to process_can_queues().
 * Larger batches:
 * - Reduce mutex lock/unlock overhead
 * - Improve cache locality
 * - Better throughput
 *
 * With 4000-message buffers, 200-message batches provide:
 * - 20 cycles to drain full buffer
 * - 5ms per batch at 40 msg/ms processing rate
 *
 * Stack usage: 200 √ó sizeof(can_msg_t*) = 200 √ó 8 = 1.6 KB ‚Üê Acceptable
 *
 * History:
 * - Original: 100
 * - Increased: 200 - Nov 7, 2025
 */
#define MAX_BATCH_SIZE              200
```

#### Step 1.1.6: Update Fairness Limit (Recommended)

**File**: `canbus/can_unified_queue.h`
**Line**: 70
**Current**: 35
**New**: 60

**Exact Change**:
```c
// Line 70 BEFORE:
#define MAX_PER_BUS_PER_BATCH       35      /**< Fairness limit per bus per batch */

// Line 70 AFTER:
/**
 * Fairness Limit Per Bus Per Batch
 *
 * Maximum messages from single bus allowed in one batch.
 * Prevents bus monopolization while allowing good throughput.
 *
 * Calculation:
 * - MAX_BATCH_SIZE = 200
 * - 3 buses
 * - Equal distribution: 200 / 3 ‚âà 67 per bus
 * - Set to 60 for safety margin
 *
 * With 60 per bus:
 * - Worst case: 60 + 60 + 60 = 180 messages (< 200 batch size) ‚úì
 * - Ensures no single bus dominates
 *
 * History:
 * - Original: 35 (for 100 batch)
 * - Increased: 60 (for 200 batch) - Nov 7, 2025
 */
#define MAX_PER_BUS_PER_BATCH       60
```

#### Step 1.2: Build Stage 1

```bash
cd /home/greg/iMatrix/iMatrix_Client/iMatrix
pwd  # Should be in iMatrix directory
git status  # Should show modified files

# Build
cd ../Fleet-Connect-1/build  # Or wherever your build directory is
make clean
make -j$(nproc) 2>&1 | tee build_stage1.log

# Check for errors
echo $?
# Should be 0 (success)

# Check for warnings related to our changes
grep -i "can_msg_pool\|unified_queue\|max_batch" build_stage1.log
# Should be clean (no warnings about these)
```

#### Step 1.3: Validate Memory Allocation

```bash
# Check binary size
ls -lh Fleet-Connect-1 imatrix_gateway
# Note the size

# Check memory maps (optional)
nm Fleet-Connect-1 | grep "can0_msg_pool\|can1_msg_pool\|can2_msg_pool"
# Should show symbols

# Calculate expected size
# 3 buses √ó 4000 msg √ó 24 bytes = 288 KB for ring buffers
# Unified queue: malloc(12000 √ó 8) = 96 KB at runtime
# Total: ~384 KB increase
```

#### Step 1.4: Deploy and Initial Test

```bash
# Stop running instance
killall imatrix_gateway 2>/dev/null

# Start with monitoring
./imatrix_gateway > /tmp/stage1_test.txt 2>&1 &
PID=$!
echo "Started PID: $PID"

# Wait for initialization
sleep 10

# Check it's running
ps -p $PID
# Should show process

# Initial stats
echo "can server" | nc localhost 23232 > /tmp/stage1_initial.txt 2>&1
cat /tmp/stage1_initial.txt

# Look for:
# Ring Buffer:
#   Total Size:            4000 messages  ‚Üê Should show 4000!
#   Free Messages:         3xxx           ‚Üê Should be high initially
```

#### Step 1.5: Monitor Performance Over Time

```bash
# Monitor every 60 seconds for 10 minutes
for i in {1..10}; do
    echo "=== Minute $i ===" | tee -a /tmp/stage1_monitoring.txt
    echo "can server" | nc localhost 23232 | tee -a /tmp/stage1_monitoring.txt
    sleep 60
done

# Analyze results
grep "Drop Rate:" /tmp/stage1_monitoring.txt
grep "In Use:" /tmp/stage1_monitoring.txt

# Calculate improvement
```

#### Step 1.6: Validate Stage 1 Success

**Success Criteria**:
```bash
# Extract metrics from last reading
DROPS_BEFORE=942605
DROPS_AFTER=$(grep "Dropped" /tmp/stage1_monitoring.txt | tail -1 | awk '{print $4}')
DROP_RATE=$(grep "Drop Rate:" /tmp/stage1_monitoring.txt | tail -1 | awk '{print $3}')
BUFFER_PCT=$(grep "In Use:" /tmp/stage1_monitoring.txt | tail -1 | grep -oP '\d+(?=%)')

echo "Drops Before: $DROPS_BEFORE (90.5%)"
echo "Drops After Stage 1: $DROPS_AFTER"
echo "Current Drop Rate: $DROP_RATE drops/sec (was 566)"
echo "Buffer Usage: $BUFFER_PCT% (was 92%)"

# Success if:
# - Drop rate < 150 drops/sec (< 20% assuming similar traffic)
# - Buffer usage < 70%
# - System stable for 10 minutes
```

**If Stage 1 Fails**:
- Drops still > 150/sec ‚Üí Processing too slow ‚Üí Must do Stage 2+3
- Buffer > 80% ‚Üí Try 8000 instead of 4000
- System crashes ‚Üí Memory issue ‚Üí Rollback

---

## üìã STAGE 2: ASYNCHRONOUS LOGGING QUEUE

**Duration**: 6 hours (4hr implementation + 2hr testing)
**Files Created**: 2 new files
**Files Modified**: 1
**Lines Added**: ~600
**Risk Level**: ‚¨ú‚¨ú‚¨ú‚¨õ‚¨õ (3/5 - Medium - Threading complexity)

### Step 2.1: Create Async Log Queue Header

**New File**: `iMatrix/cli/async_log_queue.h`
**Template**: Use `templates/blank.h`
**Content**: [See detailed structure above in the plan]

**Creation Steps**:
```bash
cd /home/greg/iMatrix/iMatrix_Client/iMatrix

# Copy template
cp templates/blank.h cli/async_log_queue.h

# Edit file (insert full header content from plan)

# Verify syntax
gcc -c -fsyntax-only cli/async_log_queue.h
```

### Step 2.2: Create Async Log Queue Implementation

**New File**: `iMatrix/cli/async_log_queue.c`
**Template**: Use `templates/blank.c`
**Content**: [Full implementation from plan]

**Key Functions to Implement**:

**2.2.1: async_log_queue_init()**
```c
imx_result_t async_log_queue_init(async_log_queue_t *queue, uint32_t capacity)
{
    /* Allocate message buffer */
    queue->messages = (log_message_t *)calloc(capacity, sizeof(log_message_t));
    if (queue->messages == NULL) {
        return IMX_OUT_OF_MEMORY;
    }

    /* Initialize mutex */
    pthread_mutexattr_t attr;
    pthread_mutexattr_init(&attr);
    pthread_mutexattr_settype(&attr, PTHREAD_MUTEX_NORMAL);

    if (pthread_mutex_init(&queue->mutex, &attr) != 0) {
        free(queue->messages);
        return IMX_ERROR;
    }

    pthread_mutexattr_destroy(&attr);

    /* Initialize state */
    queue->capacity = capacity;
    queue->head = 0;
    queue->tail = 0;
    queue->count = 0;
    queue->total_enqueued = 0;
    queue->total_dequeued = 0;
    queue->total_dropped = 0;
    queue->max_depth = 0;
    queue->drop_on_overflow = 1;  /* Drop oldest */

    return IMX_SUCCESS;
}
```

**2.2.2: async_log_enqueue() - CRITICAL PERFORMANCE PATH**
```c
imx_result_t async_log_enqueue(async_log_queue_t *queue,
                                uint8_t severity,
                                const char *format,
                                va_list args)
{
    if (queue == NULL || format == NULL) {
        return IMX_INVALID_PARAMETER;
    }

    /*
     * CRITICAL: Format message BEFORE acquiring lock
     * This minimizes mutex hold time
     */
    char formatted[LOG_MSG_MAX_LENGTH];
    int len = vsnprintf(formatted, sizeof(formatted), format, args);
    if (len < 0) {
        return IMX_ERROR;
    }

    /* Get timestamp before lock */
    struct timespec ts;
    clock_gettime(CLOCK_REALTIME, &ts);

    /*
     * Lock for minimum time - just to update indices
     */
    pthread_mutex_lock(&queue->mutex);

    /* Check if full */
    if (queue->count >= queue->capacity) {
        /* Drop message - no blocking */
        queue->total_dropped++;
        pthread_mutex_unlock(&queue->mutex);
        return IMX_QUEUE_FULL;
    }

    /* Copy to queue entry */
    log_message_t *entry = &queue->messages[queue->head];
    entry->timestamp = ts;
    entry->severity = severity;
    memcpy(entry->message, formatted, LOG_MSG_MAX_LENGTH);

    /* Update indices */
    queue->head = (queue->head + 1) % queue->capacity;
    queue->count++;
    queue->total_enqueued++;

    if (queue->count > queue->max_depth) {
        queue->max_depth = queue->count;
    }

    pthread_mutex_unlock(&queue->mutex);

    return IMX_SUCCESS;
}
```

**2.2.3: async_log_flush() - Called from Main Loop**
```c
uint32_t async_log_flush(async_log_queue_t *queue, uint32_t max_count)
{
    if (queue == NULL) {
        return 0;
    }

    uint32_t printed = 0;
    uint32_t target = (max_count == 0) ? queue->count : max_count;

    while (printed < target) {
        pthread_mutex_lock(&queue->mutex);

        if (queue->count == 0) {
            pthread_mutex_unlock(&queue->mutex);
            break;  /* Queue empty */
        }

        /* Copy message (minimize lock time) */
        log_message_t entry = queue->messages[queue->tail];
        queue->tail = (queue->tail + 1) % queue->capacity;
        queue->count--;
        queue->total_dequeued++;

        pthread_mutex_unlock(&queue->mutex);

        /*
         * Print OUTSIDE lock (can block on I/O)
         * This is the key - I/O blocking doesn't affect producers
         */
        printf("[%ld.%03ld] %s",
               (long)entry.timestamp.tv_sec,
               entry.timestamp.tv_nsec / 1000000,
               entry.message);

        printed++;
    }

    return printed;
}
```

**2.2.4: Global Queue Management**
```c
/* Global instance */
static async_log_queue_t g_log_queue;
static bool g_log_queue_initialized = false;

imx_result_t init_global_log_queue(void)
{
    if (g_log_queue_initialized) {
        return IMX_SUCCESS;
    }

    imx_result_t result = async_log_queue_init(&g_log_queue, LOG_QUEUE_CAPACITY);
    if (result == IMX_SUCCESS) {
        g_log_queue_initialized = true;
        printf("[LOG QUEUE] Initialized with %u message capacity (%.1f MB)\r\n",
               LOG_QUEUE_CAPACITY,
               (LOG_QUEUE_CAPACITY * sizeof(log_message_t)) / (1024.0 * 1024.0));
    }

    return result;
}

async_log_queue_t* get_global_log_queue(void)
{
    return g_log_queue_initialized ? &g_log_queue : NULL;
}

void destroy_global_log_queue(void)
{
    if (g_log_queue_initialized) {
        async_log_destroy(&g_log_queue);
        g_log_queue_initialized = false;
    }
}
```

### Step 2.3: Modify imx_cli_log_printf

**File**: `iMatrix/cli/interface.c`
**Current**: Lines 180-220 (approximately)

**Find current implementation**:
```bash
grep -A30 "void imx_cli_log_printf" cli/interface.c | head -35
```

**BEFORE** (current synchronous version):
```c
void imx_cli_log_printf(bool print_time, char *format, ...)
{
    imx_time_t time_ms;
    /* ... timestamp logic ... */

    va_list args;
    va_start(args, format);

    /* ... formatting ... */

    vprintf(format, args);  ‚Üê BLOCKS ON I/O!

    va_end(args);
}
```

**AFTER** (async version):
```c
/**
 * @brief Log formatted message with optional timestamp
 *
 * PERFORMANCE CRITICAL CHANGE:
 * This function now enqueues messages to async log queue instead of
 * printing directly. This prevents I/O blocking in CAN processing,
 * network handling, and other performance-critical paths.
 *
 * The CLI thread dequeues and prints asynchronously via async_log_flush().
 *
 * Fallback: If async queue not initialized, prints directly (startup phase).
 *
 * @param print_time Whether to include timestamp (ignored - queue adds timestamp)
 * @param format Printf-style format string
 * @param ... Variable arguments
 * @return None
 */
void imx_cli_log_printf(bool print_time, char *format, ...)
{
    /* Get global log queue */
    extern async_log_queue_t* get_global_log_queue(void);
    async_log_queue_t *log_queue = get_global_log_queue();

    va_list args;
    va_start(args, format);

    if (log_queue != NULL) {
        /*
         * ASYNC PATH: Enqueue to log queue
         * This is NON-BLOCKING and fast (~10 microseconds)
         */
        imx_result_t result = async_log_enqueue(log_queue, 1, format, args);

        if (result == IMX_QUEUE_FULL) {
            /* Log queue full - message dropped */
            /* Note: Can't log this without recursion! */
            /* Monitored via async_log_get_stats() */
        }
    } else {
        /*
         * FALLBACK PATH: Direct print (used during early startup)
         * After init_global_log_queue() called, async path is used
         */
        if (print_time) {
            imx_time_t time_ms;
            imx_time_get_time(&time_ms);
            printf("[%0.4f] ", (float)time_ms / 1000.0);
        }

        vprintf(format, args);
    }

    va_end(args);
}
```

**Compatibility Verification**:
```bash
# Find all uses of imx_cli_log_printf
grep -r "imx_cli_log_printf" --include="*.c" | wc -l

# Should be 100+ uses
# ALL will automatically use async queue after this change
# NO code changes needed in calling code
```

### Step 2.4: Add Log Queue Initialization

**File**: `iMatrix/imatrix_interface.c`
**Function**: `imatrix_start()`
**Location**: Early in startup, before other subsystems

**Add**:
```c
void imatrix_start(void)
{
    /* ... existing early initialization ... */

    /*
     * Initialize async log queue EARLY
     * Must be done before any subsystem that might call imx_cli_log_printf()
     */
    extern imx_result_t init_global_log_queue(void);
    imx_result_t log_init_result = init_global_log_queue();

    if (log_init_result != IMX_SUCCESS) {
        printf("ERROR: Failed to initialize async log queue (code %d)\r\n", log_init_result);
        printf("Falling back to synchronous logging - performance will be reduced\r\n");
        /* Continue anyway - will use fallback direct printing */
    }

    /* ... rest of initialization ... */
    /* All subsequent imx_cli_log_printf() calls will use async queue */
}
```

### Step 2.5: Add Log Queue Flushing to Main Loop

**File**: Find main loop (likely `imatrix_interface.c` or Fleet-Connect-1 main file)

**Search for main loop**:
```bash
grep -rn "while.*true\|while.*1" --include="*.c" | grep -i "main\|loop"
```

**Add to main loop iteration**:
```c
void main_processing_loop(void)
{
    while (system_running) {
        imx_time_t current_time;
        imx_time_get_time(&current_time);

        /* Process network */
        process_network(current_time);

        /* Process uploads */
        imatrix_upload(current_time);

        /* Process other subsystems */
        /* ... */

        /*
         * NEW: Flush async log queue
         * Print up to 100 log messages per cycle
         * This prevents log queue from filling up
         * while allowing I/O to happen in main thread (OK to block here)
         */
        extern async_log_queue_t* get_global_log_queue(void);
        async_log_queue_t *log_queue = get_global_log_queue();
        if (log_queue != NULL) {
            uint32_t printed = async_log_flush(log_queue, 100);

            /* Monitor log queue health */
            static uint32_t last_log_check = 0;
            if (current_time - last_log_check > 10000) {  /* Every 10 seconds */
                uint32_t depth;
                uint64_t dropped;
                async_log_get_stats(log_queue, &depth, &dropped);

                if (depth > 8000) {  /* 80% of 10000 capacity */
                    printf("WARNING: Log queue filling up (depth=%u, dropped=%llu)\r\n",
                           depth, dropped);
                }

                last_log_check = current_time;
            }
        }

        /* Continue loop */
    }
}
```

### Step 2.6: Add Log Queue Stats CLI Command

**File**: Find CLI command handler (likely `cli/cli.c` or similar)

**Add Command**:
```c
/* In CLI command table */
{"logstats", cli_log_stats, "Display async log queue statistics"},

/* Handler implementation */
void cli_log_stats(uint16_t arg)
{
    UNUSED_PARAMETER(arg);

    extern async_log_queue_t* get_global_log_queue(void);
    async_log_queue_t *queue = get_global_log_queue();

    if (queue == NULL) {
        imx_cli_print("Async log queue not initialized (using direct logging)\r\n");
        return;
    }

    uint32_t depth;
    uint64_t dropped;
    async_log_get_stats(queue, &depth, &dropped);

    pthread_mutex_lock(&queue->mutex);
    uint32_t capacity = queue->capacity;
    uint64_t enqueued = queue->total_enqueued;
    uint64_t dequeued = queue->total_dequeued;
    uint32_t max_depth = queue->max_depth;
    pthread_mutex_unlock(&queue->mutex);

    float usage_pct = (float)depth * 100 / capacity;
    float max_pct = (float)max_depth * 100 / capacity;

    imx_cli_print("\r\n=== Async Log Queue Statistics ===\r\n");
    imx_cli_print("Capacity:        %u messages (%.1f MB)\r\n",
                  capacity,
                  (capacity * sizeof(log_message_t)) / (1024.0 * 1024.0));
    imx_cli_print("Current Depth:   %u (%.1f%%)\r\n", depth, usage_pct);
    imx_cli_print("Max Depth:       %u (%.1f%%)\r\n", max_depth, max_pct);
    imx_cli_print("Total Enqueued:  %llu\r\n", enqueued);
    imx_cli_print("Total Dequeued:  %llu\r\n", dequeued);
    imx_cli_print("Total Dropped:   %llu\r\n", dropped);

    if (dropped > 0) {
        imx_cli_print("\r\nWARNING: %llu log messages dropped!\r\n", dropped);
        imx_cli_print("Consider: Reduce logging verbosity or increase LOG_QUEUE_CAPACITY\r\n");
    }

    if (usage_pct > 80.0f) {
        imx_cli_print("\r\nWARNING: Log queue >80%% full (%.1f%%)\r\n", usage_pct);
    }

    imx_cli_print("======================================\r\n\r\n");
}
```

### Step 2.7: Update CMakeLists.txt

**File**: `iMatrix/CMakeLists.txt`

**Find SOURCES section**, add:
```cmake
# Async logging queue
cli/async_log_queue.c
cli/async_log_queue.h
```

### Step 2.8: Build and Test Stage 2

```bash
make clean
make -j$(nproc) 2>&1 | tee build_stage2.log

# Check for async_log_queue symbols
nm imatrix_gateway | grep async_log
# Should show: async_log_queue_init, async_log_enqueue, async_log_flush

# Run
./imatrix_gateway > /tmp/stage2_test.txt 2>&1 &
PID=$!

# Verify log queue initialized
grep "LOG QUEUE.*Initialized" /tmp/stage2_test.txt
# Should see initialization message

# Check logs still appear
tail -f /tmp/stage2_test.txt
# Logs should print (with slight async delay)

# Check queue stats
echo "logstats" | nc localhost 23232
# Should show queue statistics
```

**Stage 2 Success Criteria**:
- ‚úÖ All logs print asynchronously
- ‚úÖ Log queue depth < 50%
- ‚úÖ Zero dropped log messages
- ‚úÖ CAN drop rate reduced (printf no longer blocking)
- ‚úÖ System stable

---

## üìã STAGE 3: DEDICATED CAN PROCESSING THREAD

**Duration**: 8 hours (6hr implementation + 2hr testing)
**Files Created**: 1 (can_processing_thread.c)
**Files Modified**: 3
**Lines Added**: ~300
**Risk Level**: ‚¨ú‚¨ú‚¨ú‚¨ú‚¨õ (4/5 - Medium-High - Critical threading)

### Step 3.1: Create Processing Thread Module

**New File**: `iMatrix/canbus/can_processing_thread.c`

```c
/*
 * Copyright 2025, iMatrix Systems, Inc.. All Rights Reserved.
 */

/**
 * @file can_processing_thread.c
 * @brief Dedicated CAN message processing thread
 * @date November 7, 2025
 * @author Greg Phillips
 *
 * Implements a dedicated pthread for continuous CAN message processing.
 * Decouples CAN handling from main application loop to prevent CAN
 * bursts from blocking network, uploads, and other critical tasks.
 *
 * Architecture:
 * - Runs in infinite loop until shutdown signal
 * - Dequeues batches from unified queue
 * - Processes messages (signal extraction, MM2 writes)
 * - Returns messages to ring buffer pools
 * - Updates statistics
 * - Sleeps 1ms between iterations (prevents CPU spinning)
 *
 * Benefits:
 * - Main loop never blocked by CAN processing
 * - Can handle burst traffic without affecting other subsystems
 * - Dedicated CPU time for CAN (can set thread priority)
 * - Simpler main loop (one less responsibility)
 *
 * @version 1.0
 * @bug None known
 * @todo Monitor thread health/heartbeat
 * @warning Must call stop_can_processing_thread() before exit
 */

#include <pthread.h>
#include <unistd.h>
#include <time.h>

#include "can_processing_thread.h"
#include "can_utils.h"
#include "can_unified_queue.h"
#include "can_structs.h"

/******************************************************
 *               Module Variables
 ******************************************************/

static pthread_t can_processing_thread;
static volatile bool can_thread_running = false;
static volatile bool can_thread_shutdown_requested = false;

/* Thread statistics */
static struct {
    uint64_t total_batches_processed;
    uint64_t total_messages_processed;
    uint64_t total_processing_time_us;
    uint32_t current_messages_per_sec;
    imx_time_t last_stats_time;
} thread_stats;

/******************************************************
 *               Function Definitions
 ******************************************************/

/**
 * @brief CAN processing thread entry point
 *
 * Main loop for dedicated CAN processing.
 * Runs continuously until shutdown requested.
 *
 * @param arg Thread argument (unused)
 * @return NULL on exit
 */
static void* can_processing_thread_main(void *arg)
{
    UNUSED_PARAMETER(arg);

    /* Set thread name for debugging */
    #ifdef __linux__
    pthread_setname_np(pthread_self(), "can_process");
    #endif

    /* Initialize thread stats */
    memset(&thread_stats, 0, sizeof(thread_stats));
    imx_time_get_time(&thread_stats.last_stats_time);

    ASYNC_LOG(1, "[CAN THREAD] Processing thread started\r\n");

    /*
     * Main processing loop
     * Continues until shutdown requested
     */
    while (!can_thread_shutdown_requested) {
        /* Get current time */
        imx_time_t current_time;
        imx_time_get_time(&current_time);

        /*
         * Process CAN queues
         * This function dequeues, processes, and returns messages
         * Defined in can_utils.c
         */
        extern void process_can_queues(imx_time_t current_time);
        process_can_queues(current_time);

        /*
         * Update CAN statistics
         * Calculates rates, buffer utilization, etc.
         * Defined in can_utils.c
         */
        extern void imx_update_can_statistics(imx_time_t current_time);
        imx_update_can_statistics(current_time);

        /*
         * Brief sleep to prevent CPU spinning
         * 1ms sleep allows:
         * - Up to 1000 iterations per second
         * - Other threads to run
         * - CPU to idle if no CAN traffic
         *
         * At 2000 fps, messages accumulate:
         * - 2 messages per 1ms sleep
         * - Acceptable with large buffers
         */
        struct timespec sleep_time = {0, 1000000};  /* 1ms = 1,000,000 ns */
        nanosleep(&sleep_time, NULL);

        /* Update thread stats every 10 seconds */
        if (current_time - thread_stats.last_stats_time > 10000) {
            /* Calculate current rate */
            /* (Implementation details) */
            thread_stats.last_stats_time = current_time;
        }
    }

    ASYNC_LOG(1, "[CAN THREAD] Processing thread exiting\r\n");

    can_thread_running = false;
    return NULL;
}

/**
 * @brief Start CAN processing thread
 *
 * Creates and starts the dedicated CAN processing thread.
 * Should be called after CAN bus initialization.
 *
 * @return true if thread started successfully, false on error
 */
bool start_can_processing_thread(void)
{
    if (can_thread_running) {
        ASYNC_LOG(2, "[CAN THREAD] Already running\r\n");
        return true;
    }

    can_thread_shutdown_requested = false;

    pthread_attr_t attr;
    pthread_attr_init(&attr);
    pthread_attr_setdetachstate(&attr, PTHREAD_CREATE_JOINABLE);

    /*
     * Optional: Set thread priority
     * Uncomment if want realtime priority (requires root or CAP_SYS_NICE)
     */
    /*
    struct sched_param param;
    param.sched_priority = sched_get_priority_max(SCHED_FIFO) - 10;
    pthread_attr_setschedpolicy(&attr, SCHED_FIFO);
    pthread_attr_setschedparam(&attr, &param);
    */

    int result = pthread_create(&can_processing_thread, &attr, can_processing_thread_main, NULL);

    pthread_attr_destroy(&attr);

    if (result != 0) {
        ASYNC_LOG(3, "[CAN THREAD] Failed to create thread: %d\r\n", result);
        return false;
    }

    can_thread_running = true;
    ASYNC_LOG(1, "[CAN THREAD] Started successfully\r\n");

    return true;
}

/**
 * @brief Stop CAN processing thread
 *
 * Signals thread to exit and waits for completion.
 * Should be called during system shutdown.
 *
 * @param timeout_ms Maximum time to wait for thread exit
 * @return true if thread exited cleanly, false if timeout
 */
bool stop_can_processing_thread(uint32_t timeout_ms)
{
    if (!can_thread_running) {
        return true;  /* Already stopped */
    }

    ASYNC_LOG(1, "[CAN THREAD] Requesting shutdown...\r\n");

    /* Signal shutdown */
    can_thread_shutdown_requested = true;

    /* Wait for thread to exit */
    struct timespec timeout;
    clock_gettime(CLOCK_REALTIME, &timeout);
    timeout.tv_sec += timeout_ms / 1000;
    timeout.tv_nsec += (timeout_ms % 1000) * 1000000;

    /* Join thread (wait for exit) */
    int result = pthread_timedjoin_np(can_processing_thread, NULL, &timeout);

    if (result == 0) {
        ASYNC_LOG(1, "[CAN THREAD] Exited cleanly\r\n");
        return true;
    } else if (result == ETIMEDOUT) {
        ASYNC_LOG(2, "[CAN THREAD] Timeout waiting for exit\r\n");
        /* Consider pthread_cancel as last resort */
        return false;
    } else {
        ASYNC_LOG(3, "[CAN THREAD] Join error: %d\r\n", result);
        return false;
    }
}

/**
 * @brief Get thread statistics
 *
 * @param messages_processed [out] Total messages processed
 * @param avg_rate [out] Average processing rate (messages/sec)
 * @return true if thread running, false otherwise
 */
bool get_can_thread_stats(uint64_t *messages_processed, float *avg_rate)
{
    if (!can_thread_running) {
        return false;
    }

    if (messages_processed) {
        *messages_processed = thread_stats.total_messages_processed;
    }

    if (avg_rate && thread_stats.total_processing_time_us > 0) {
        *avg_rate = (float)thread_stats.total_messages_processed * 1000000 /
                    thread_stats.total_processing_time_us;
    }

    return true;
}
```

**Header File**: `iMatrix/canbus/can_processing_thread.h`

```c
#ifndef CAN_PROCESSING_THREAD_H
#define CAN_PROCESSING_THREAD_H

#include <stdbool.h>
#include <stdint.h>

/**
 * @brief Start dedicated CAN processing thread
 * @return true if started, false on error
 */
bool start_can_processing_thread(void);

/**
 * @brief Stop CAN processing thread
 * @param timeout_ms Max wait time
 * @return true if exited cleanly
 */
bool stop_can_processing_thread(uint32_t timeout_ms);

/**
 * @brief Get thread statistics
 * @param messages_processed [out] Total processed
 * @param avg_rate [out] Avg rate (msg/sec)
 * @return true if running
 */
bool get_can_thread_stats(uint64_t *messages_processed, float *avg_rate);

#endif /* CAN_PROCESSING_THREAD_H */
```

### Step 3.2: Modify CAN Initialization

**File**: `iMatrix/canbus/can_utils.c` or `can_process.c`
**Function**: `setup_can_bus()` or similar

**ADD at end of initialization**:
```c
bool setup_can_bus(void) {
    /* ... existing initialization ... */

    /* Initialize unified queue */
    result = unified_queue_init(&unified_queue, UNIFIED_QUEUE_SIZE);
    if (result != IMX_SUCCESS) {
        PRINTF("[CAN BUS - Error initializing unified queue]\r\n");
        return false;
    }

    /* ... statistics initialization ... */

    /*
     * NEW: Start dedicated CAN processing thread
     * This removes CAN processing from main loop
     */
    extern bool start_can_processing_thread(void);
    if (!start_can_processing_thread()) {
        PRINTF("[CAN BUS - ERROR: Failed to start processing thread]\r\n");
        PRINTF("[CAN BUS - Falling back to main loop processing]\r\n");
        /* Continue anyway - can fall back to main loop if needed */
    }

    return true;
}
```

### Step 3.3: Remove from Main Loop

**File**: Search for `process_can_queues` call in main loop

```bash
grep -rn "process_can_queues" --include="*.c" | grep -v "canbus/"
```

**Current main loop has**:
```c
process_can_queues(current_time);
imx_update_can_statistics(current_time);
```

**Comment out or remove**:
```c
/*
 * CAN processing moved to dedicated thread (Stage 3)
 * See: canbus/can_processing_thread.c
 *
 * If thread fails to start, uncomment these lines as fallback:
 */
// process_can_queues(current_time);
// imx_update_can_statistics(current_time);
```

### Step 3.4: Add Thread Health Monitoring

**In main loop or separate monitor thread**:
```c
/* Check CAN thread health every 30 seconds */
static imx_time_t last_health_check = 0;
if (current_time - last_health_check > 30000) {
    extern bool get_can_thread_stats(...);
    uint64_t messages;
    float rate;

    if (get_can_thread_stats(&messages, &rate)) {
        ASYNC_LOG(1, "[CAN THREAD HEALTH] Processed %llu messages (%.1f msg/sec)\r\n",
                  messages, rate);
    } else {
        ASYNC_LOG(3, "[CAN THREAD HEALTH] Thread not running!\r\n");
        /* Consider restarting thread */
    }

    last_health_check = current_time;
}
```

### Step 3.5: Update CMakeLists.txt

```cmake
# Add new thread module
canbus/can_processing_thread.c
canbus/can_processing_thread.h
```

### Step 3.6: Test Stage 3

```bash
# Build
make clean && make

# Run
./imatrix_gateway &
PID=$!

# Check threads
ps -T -p $PID
# Should show:
# - Main thread
# - tcp_server thread (can_server)
# - can_process thread (NEW!)

# Check thread CPU usage
top -H -p $PID
# can_process should show 5-20% CPU when traffic present

# Monitor CAN stats
> can server
# Should show improved performance

# Monitor for 10 minutes
# Check stability
```

---

## üéØ EXPECTED RESULTS BY STAGE

| Metric | Current | Stage 1 | Stage 2 | Stage 3 | Stage 4+5 |
|--------|---------|---------|---------|---------|-----------|
| **Drop Rate** | 90% | 20% | 15% | 5% | <1% |
| **Drops/sec** | 566 | 150 | 100 | 30 | <10 |
| **Buffer Usage** | 92% | 60% | 50% | 40% | 30% |
| **Processing** | Main loop | Main loop | Main loop | Dedicated | Optimized |
| **Logging** | Blocking | Blocking | Async | Async | Async |

---

## üß™ COMPREHENSIVE TESTING MATRIX

### Test 1: Buffer Increase (Stage 1)
**Duration**: 30 minutes
**Traffic**: Normal (829 fps)

| Check | Command | Expected | Pass/Fail |
|-------|---------|----------|-----------|
| Buffer size | `can server` | 4000 messages | ‚òê |
| Drop rate | `can server` | < 150 drops/sec | ‚òê |
| Buffer usage | `can server` | < 70% | ‚òê |
| Stability | Run 10 min | No crashes | ‚òê |

### Test 2: Async Logging (Stage 2)
**Duration**: 1 hour
**Traffic**: Normal + verbose logging

| Check | Command | Expected | Pass/Fail |
|-------|---------|----------|-----------|
| Log queue init | Check startup | "LOG QUEUE Initialized" | ‚òê |
| Logs print | `tail -f logs` | Messages appear | ‚òê |
| Queue depth | `logstats` | < 50% | ‚òê |
| No drops | `logstats` | Dropped = 0 | ‚òê |
| CAN improvement | `can server` | Drop rate further reduced | ‚òê |

### Test 3: Processing Thread (Stage 3)
**Duration**: 2 hours
**Traffic**: Burst patterns

| Check | Command | Expected | Pass/Fail |
|-------|---------|----------|-----------|
| Thread exists | `ps -T -p $PID` | can_process shown | ‚òê |
| Thread CPU | `top -H` | 5-20% CPU | ‚òê |
| Main loop freed | Monitor responsiveness | CLI remains responsive | ‚òê |
| CAN performance | `can server` | < 5% drops | ‚òê |
| No deadlocks | Run 2 hours | Stable | ‚òê |

---

**Plan Status**: Complete and ready for approval

**Files to Create**: 4 new files
**Files to Modify**: 6 existing files
**Total LOC**: ~1,000 lines across all stages

**Ready to implement upon your approval!**

